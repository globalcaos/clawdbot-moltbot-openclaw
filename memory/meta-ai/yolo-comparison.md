# YOLO Architecture Comparison ‚Äî Living Document

**Last Updated:** 2026-02-05
**Maintained by:** JarvisOne (Meta-AI Research Cron)

---

## Why YOLO26 is Special

YOLO26 (September 2025, Ultralytics) represents a paradigm shift in the YOLO family. Here's what makes it different:

### üéØ Key Architectural Innovations

| Feature | What It Does | Why It Matters |
|---------|--------------|----------------|
| **NMS-Free Inference** | Native end-to-end detection without Non-Maximum Suppression | Eliminates post-processing latency, simplifies deployment |
| **No DFL (Distribution Focal Loss)** | Simplified bounding box regression | Faster exports, better hardware compatibility (ONNX, TensorRT, CoreML) |
| **ProgLoss** | Progressive loss balancing during training | More stable convergence, better small object detection |
| **STAL** | Small-Target-Aware Label Assignment | Dramatically improves detection of small objects |
| **MuSGD Optimizer** | Hybrid of SGD + Muon (from LLM training) | Faster, more stable training convergence |

### üî¨ How NMS-Free Works

Traditional YOLO:
```
Image ‚Üí CNN ‚Üí Many Predictions ‚Üí NMS Post-Processing ‚Üí Final Boxes
                                      ‚Üë
                            (Slow, tunable IoU threshold)
```

YOLO26:
```
Image ‚Üí CNN ‚Üí Learned Suppression ‚Üí Final Boxes
                    ‚Üë
        (End-to-end, no hyperparameters)
```

The model learns to output non-overlapping predictions directly, eliminating the handcrafted NMS step.

### üßÆ ProgLoss (Progressive Loss Balancing)

Instead of fixed loss weights throughout training:
- **Early training:** Emphasize classification (what is it?)
- **Mid training:** Balance classification + localization
- **Late training:** Emphasize localization (where exactly?)

This mimics how humans learn ‚Äî first recognize, then refine position.

### üéØ STAL (Small-Target-Aware Label Assignment)

Previous YOLO versions struggled with small objects because:
1. Small objects produce weak feature activations
2. Standard label assignment underweights them

STAL:
- Dynamically adjusts positive sample assignment based on object size
- Larger assignment radius for small objects
- More anchor points assigned to small targets

---

## Benchmark Comparison Table

| Model | mAP@50 | mAP@50-95 | Params | FLOPs | Latency (T4) | Edge Ready |
|-------|--------|-----------|--------|-------|--------------|------------|
| **YOLO26n** | 37.3% | ‚Äî | 2.6M | 6.5G | 1.2ms | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **YOLO26s** | 44.9% | ‚Äî | 9.1M | 21.5G | 2.0ms | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **YOLO26m** | 50.0% | ‚Äî | 20.1M | 67.1G | 4.3ms | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **YOLO26l** | 52.8% | ‚Äî | 43.6M | 155.4G | 7.2ms | ‚≠ê‚≠ê‚≠ê |
| YOLO11m | 51.5% | 37.2% | 20.1M | 68.0G | 4.7ms | ‚≠ê‚≠ê‚≠ê‚≠ê |
| YOLOv10m | 51.1% | 38.0% | 15.4M | 59.1G | 4.9ms | ‚≠ê‚≠ê‚≠ê‚≠ê |
| YOLOv8m | 50.2% | 36.9% | 25.9M | 78.9G | 5.3ms | ‚≠ê‚≠ê‚≠ê |
| YOLOv12m | 52.5% | 39.1% | 20.2M | 67.5G | 5.5ms* | ‚≠ê‚≠ê‚≠ê |
| RT-DETR-M | 54.7% | ‚Äî | ‚Äî | ‚Äî | 4.5ms | ‚≠ê‚≠ê‚≠ê |

*YOLOv12 still uses NMS post-processing

### Key Observations

1. **YOLO26 matches accuracy with less latency** ‚Äî NMS removal shows real gains
2. **Smaller models now viable** ‚Äî YOLO26n at 1.2ms opens IoT/wearable use cases
3. **RT-DETR competition** ‚Äî Transformer-based detection catching up, but heavier
4. **Edge deployment winner** ‚Äî YOLO26 explicitly optimized for Jetson Orin/Nano

---

## Task Support Comparison

| Model | Detection | Segmentation | Pose | OBB | Classification |
|-------|-----------|--------------|------|-----|----------------|
| **YOLO26** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| YOLO11 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| YOLOv10 | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |
| YOLOv8 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| RT-DETR | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |

---

## Export Format Comparison

| Model | ONNX | TensorRT | CoreML | TFLite | OpenVINO | Edge TPU |
|-------|------|----------|--------|--------|----------|----------|
| **YOLO26** | ‚úÖ Clean | ‚úÖ Optimized | ‚úÖ | ‚úÖ INT8 | ‚úÖ | ‚úÖ |
| YOLO11 | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| YOLOv12 | ‚ö†Ô∏è DFL issues | ‚ö†Ô∏è | ‚ö†Ô∏è | ‚ö†Ô∏è | ‚ö†Ô∏è | ‚ö†Ô∏è |

YOLO26's removal of DFL makes exports significantly cleaner across all platforms.

---

## Historical Evolution

```
YOLOv1 (2016) ‚Üí Single-pass detection revolution
    ‚Üì
YOLOv3 (2018) ‚Üí Multi-scale, Darknet-53
    ‚Üì
YOLOv5 (2020) ‚Üí PyTorch era, Ultralytics takes over
    ‚Üì
YOLOv8 (2023) ‚Üí Anchor-free, decoupled head
    ‚Üì
YOLO11 (2024) ‚Üí Efficiency focus, 22% fewer params than v8
    ‚Üì
YOLOv12/v13 (2024-2025) ‚Üí Attention mechanisms, still NMS-based
    ‚Üì
YOLO26 (Sept 2025) ‚Üí NMS-free, ProgLoss, STAL, MuSGD
```

---

## Relevance to Oscar's Projects

### SerraVision.ai
- **Recommended:** YOLO26m or YOLO26l
- **Why:** Multi-task (detect + segment), Jetson-optimized
- **Upgrade path:** Retrain existing YOLOv8 weights ‚Üí YOLO26

### Pallet Scan
- **Recommended:** YOLO26s + SAM3
- **Why:** YOLO26 for detection, SAM3 for segmentation by description
- **Combo:** "Detect boxes ‚Üí Segment 'wooden pallet' ‚Üí Measure"

### Gantry Robot Arm
- **Recommended:** YOLO26n (speed) + pose estimation
- **Why:** Real-time object + pose for manipulation planning
- **Integration:** Feed to MoveIt / VLA model

---

## Sources

1. [YOLO26 Paper (arXiv:2509.25164)](https://arxiv.org/abs/2509.25164)
2. [YOLO Evolution Benchmark (arXiv:2411.00201)](https://arxiv.org/abs/2411.00201)
3. [Ultralytics Model Comparison Hub](https://docs.ultralytics.com/compare/)
4. [Roboflow Best Object Detection 2025](https://blog.roboflow.com/best-object-detection-models/)

---

*This document is maintained by the Meta-AI Research cron job. Updates occur during each scan.*
